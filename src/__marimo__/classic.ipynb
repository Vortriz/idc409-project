{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {
    "marimo": {
     "name": "setup"
    }
   },
   "outputs": [],
   "source": [
    "# Initialization code that runs before all other cells\n",
    "import os\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "name": "*preprocessing"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(image_path, threshold_value=None):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)  # to reduce noise\n",
    "\n",
    "    # threshold the image to convert to binary\n",
    "    if threshold_value is None:\n",
    "        threshold_value = np.max(blur) / 2 + np.min(blur) / 2\n",
    "    _, thresholded_image = cv2.threshold(\n",
    "        blur, threshold_value, 255, cv2.THRESH_BINARY_INV\n",
    "    )\n",
    "\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {
    "marimo": {
     "name": "*find_contour"
    }
   },
   "outputs": [],
   "source": [
    "def find_contour(thresholded_image):\n",
    "    contours, _ = cv2.findContours(\n",
    "        thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    if not contours:\n",
    "        return None\n",
    "\n",
    "    # assume the largest contour is our shape\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # filter out tiny contours that are likely noise\n",
    "    if cv2.contourArea(contour) < 100:\n",
    "        return None\n",
    "\n",
    "    return contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "name": "*extract_features_from_contour"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_from_contour(contour):\n",
    "    # Hu moments\n",
    "    M = cv2.moments(contour)\n",
    "\n",
    "    if M[\"m00\"] == 0:\n",
    "        return None  # avoid divide-by-zero\n",
    "\n",
    "    hu_moments = cv2.HuMoments(M).flatten()\n",
    "    # to make them more stable and comparable\n",
    "    hu_moments = (\n",
    "        -1 * np.copysign(1.0, hu_moments) * np.log10(abs(hu_moments) + 1e-7)\n",
    "    )\n",
    "\n",
    "    # corners\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    epsilon = (\n",
    "        0.03 * perimeter\n",
    "    )  # 3% of perimeter is a good starting point for approximation\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "    num_corners = len(approx)\n",
    "\n",
    "    # solidity\n",
    "    area = M[\"m00\"]  # cv2.contourArea(contour)\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area if hull_area > 0 else 0\n",
    "\n",
    "    # aspect ratio\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    aspect_ratio = float(w) / h if h > 0 else 0\n",
    "\n",
    "    # circularity\n",
    "    circularity = (4 * np.pi * area) / (perimeter**2) if perimeter > 0 else 0\n",
    "\n",
    "    # final feature vector\n",
    "    features = np.append(\n",
    "        [num_corners, solidity, aspect_ratio, circularity], hu_moments\n",
    "    )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "name": "*extract_features"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    thresholded_image = preprocessing(image_path)\n",
    "    contour = find_contour(thresholded_image)\n",
    "    if contour is None:\n",
    "        return None\n",
    "    features = extract_features_from_contour(contour)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {
    "marimo": {
     "name": "*load_data"
    }
   },
   "outputs": [],
   "source": [
    "@mo.cache\n",
    "def load_data(dataset_path, labels):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    feature_names = [\n",
    "        \"num_corners\",\n",
    "        \"solidity\",\n",
    "        \"aspect_ratio\",\n",
    "        \"circularity\",\n",
    "        \"hu1\",\n",
    "        \"hu2\",\n",
    "        \"hu3\",\n",
    "        \"hu4\",\n",
    "        \"hu5\",\n",
    "        \"hu6\",\n",
    "        \"hu7\",\n",
    "    ]\n",
    "\n",
    "    for label in mo.status.progress_bar(\n",
    "        labels, title=f\"Loading dataset of {len(labels)} labels\"\n",
    "    ):\n",
    "        label_path = os.path.join(dataset_path, label)\n",
    "        if not os.path.isdir(label_path):\n",
    "            print(f\"Warning: Label directory not found: {label_path}\")\n",
    "            continue\n",
    "\n",
    "        for filename in mo.status.progress_bar(\n",
    "            os.listdir(label_path),\n",
    "            title=f\"Extracting features for label '{label}'\",\n",
    "            remove_on_exit=True,\n",
    "        ):\n",
    "            if filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(label_path, filename)\n",
    "                features = extract_features(image_path)\n",
    "\n",
    "                if features is not None and len(features) == len(\n",
    "                    feature_names\n",
    "                ):\n",
    "                    all_features.append(features)\n",
    "                    all_labels.append(label)\n",
    "\n",
    "    df = pd.DataFrame(all_features, columns=feature_names)\n",
    "    df[\"label\"] = all_labels\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'><marimo-progress data-title='&quot;Loading dataset of 10 labels&quot;' data-total='10' data-progress='10' data-rate='0.08' data-eta='0.0'></marimo-progress><span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Successfully loaded and processed <strong>120000</strong> samples.</span></span></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASET_DIR = mo.notebook_dir() / \"dataset_classic\"\n",
    "LABELS = [\n",
    "    \"parallelogram\",\n",
    "    \"triangle\",\n",
    "    \"pentagon\",\n",
    "    \"rectangle\",\n",
    "    \"square\",\n",
    "    \"circle\",\n",
    "    \"trapezoid\",\n",
    "    \"oval\",\n",
    "    \"semicircle\",\n",
    "    \"rhombus\",\n",
    "]\n",
    "\n",
    "data = load_data(DATASET_DIR, LABELS)\n",
    "\n",
    "mo.stop(data.empty, mo.md(\"**Error**: No data was loaded. Exiting!\"))\n",
    "mo.output.append(\n",
    "    mo.md(f\"Successfully loaded and processed **{len(data)}** samples.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"label\", axis=1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "# scale features\n",
    "# this is important for SVM, but also good practice for most models\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,  # to ensure all classes are represented in train/test splits\n",
    ")\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<marimo-ui-element object-id='bUrD-0' random-id='ba2e2000-612f-348f-2d81-3ecd7ddd4f1e'><marimo-table data-initial-value='[]' data-label='null' data-data='&quot;[{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9932595701,&#92;&quot;aspect_ratio&#92;&quot;:2.3333333333,&#92;&quot;circularity&#92;&quot;:0.6445102649,&#92;&quot;hu1&#92;&quot;:0.6684642629,&#92;&quot;hu2&#92;&quot;:1.7383069147,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:-7.0,&#92;&quot;hu7&#92;&quot;:-7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9910744936,&#92;&quot;aspect_ratio&#92;&quot;:2.4358974359,&#92;&quot;circularity&#92;&quot;:0.6208107108,&#92;&quot;hu1&#92;&quot;:0.6586770524,&#92;&quot;hu2&#92;&quot;:1.6905102784,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:7.0,&#92;&quot;hu7&#92;&quot;:7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9940087146,&#92;&quot;aspect_ratio&#92;&quot;:2.2533333333,&#92;&quot;circularity&#92;&quot;:0.6553384859,&#92;&quot;hu1&#92;&quot;:0.6750342879,&#92;&quot;hu2&#92;&quot;:1.7723044725,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:-7.0,&#92;&quot;hu7&#92;&quot;:-7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9915576192,&#92;&quot;aspect_ratio&#92;&quot;:2.4285714286,&#92;&quot;circularity&#92;&quot;:0.6295648429,&#92;&quot;hu1&#92;&quot;:0.6617286055,&#92;&quot;hu2&#92;&quot;:1.7049798696,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:-7.0,&#92;&quot;hu7&#92;&quot;:7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9943679599,&#92;&quot;aspect_ratio&#92;&quot;:2.4146341463,&#92;&quot;circularity&#92;&quot;:0.6260445571,&#92;&quot;hu1&#92;&quot;:0.6617173398,&#92;&quot;hu2&#92;&quot;:1.7046628763,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:-7.0,&#92;&quot;hu7&#92;&quot;:-7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9934831461,&#92;&quot;aspect_ratio&#92;&quot;:2.3134328358,&#92;&quot;circularity&#92;&quot;:0.6475703142,&#92;&quot;hu1&#92;&quot;:0.6696947566,&#92;&quot;hu2&#92;&quot;:1.7445703709,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:-7.0,&#92;&quot;hu7&#92;&quot;:-7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9942971486,&#92;&quot;aspect_ratio&#92;&quot;:2.2957746479,&#92;&quot;circularity&#92;&quot;:0.6503000281,&#92;&quot;hu1&#92;&quot;:0.6707155965,&#92;&quot;hu2&#92;&quot;:1.7498084775,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:-7.0,&#92;&quot;hu7&#92;&quot;:-7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9912909836,&#92;&quot;aspect_ratio&#92;&quot;:2.4222222222,&#92;&quot;circularity&#92;&quot;:0.6282424695,&#92;&quot;hu1&#92;&quot;:0.6636336123,&#92;&quot;hu2&#92;&quot;:1.7140803124,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:-7.0,&#92;&quot;hu7&#92;&quot;:-7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9936454141,&#92;&quot;aspect_ratio&#92;&quot;:2.3043478261,&#92;&quot;circularity&#92;&quot;:0.648973028,&#92;&quot;hu1&#92;&quot;:0.6701930233,&#92;&quot;hu2&#92;&quot;:1.7471234772,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:7.0,&#92;&quot;hu6&#92;&quot;:7.0,&#92;&quot;hu7&#92;&quot;:7.0},{&#92;&quot;num_corners&#92;&quot;:4.0,&#92;&quot;solidity&#92;&quot;:0.9920777818,&#92;&quot;aspect_ratio&#92;&quot;:2.3962264151,&#92;&quot;circularity&#92;&quot;:0.6349514575,&#92;&quot;hu1&#92;&quot;:0.6640546635,&#92;&quot;hu2&#92;&quot;:1.716300736,&#92;&quot;hu3&#92;&quot;:7.0,&#92;&quot;hu4&#92;&quot;:7.0,&#92;&quot;hu5&#92;&quot;:-7.0,&#92;&quot;hu6&#92;&quot;:7.0,&#92;&quot;hu7&#92;&quot;:-7.0}]&quot;' data-total-rows='120000' data-total-columns='11' data-max-columns='50' data-banner-text='&quot;&quot;' data-pagination='true' data-page-size='10' data-field-types='[[&quot;num_corners&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;solidity&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;aspect_ratio&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;circularity&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;hu1&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;hu2&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;hu3&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;hu4&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;hu5&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;hu6&quot;,[&quot;number&quot;,&quot;float64&quot;]],[&quot;hu7&quot;,[&quot;number&quot;,&quot;float64&quot;]]]' data-show-filters='true' data-show-download='true' data-show-column-summaries='true' data-show-data-types='true' data-show-page-size-selector='true' data-show-column-explorer='true' data-show-chart-builder='true' data-row-headers='[]' data-has-stable-row-id='false' data-lazy='false' data-preload='false'></marimo-table></marimo-ui-element>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'><span>Training Random Forest classifier...</span><span>Training complete.</span></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mo.output.append(\"Training Random Forest classifier...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# print(\"Training SVM classifier...\")\n",
    "# model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "mo.output.append(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'><span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Model Accuracy: <strong>99.09%</strong></span></span></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "mo.output.append(mo.md(f\"Model Accuracy: **{acc * 100:.2f}%**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "parallelogram       1.00      1.00      1.00      2400\n",
      "     triangle       1.00      1.00      1.00      2400\n",
      "     pentagon       1.00      1.00      1.00      2400\n",
      "    rectangle       1.00      1.00      1.00      2400\n",
      "       square       0.97      0.94      0.95      2400\n",
      "       circle       1.00      1.00      1.00      2400\n",
      "    trapezoid       1.00      1.00      1.00      2400\n",
      "         oval       1.00      1.00      1.00      2400\n",
      "   semicircle       1.00      1.00      1.00      2400\n",
      "      rhombus       0.94      0.97      0.96      2400\n",
      "\n",
      "     accuracy                           0.99     24000\n",
      "    macro avg       0.99      0.99      0.99     24000\n",
      " weighted avg       0.99      0.99      0.99     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mo.output.append(mo.md(\"**Classification Report:**\"))\n",
    "print(classification_report(y_test, y_pred, labels=LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "name": "*find_all_contours"
    }
   },
   "outputs": [],
   "source": [
    "def find_all_contours(thresholded_image):\n",
    "    contours, _ = cv2.findContours(\n",
    "        thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    filtered_contours = [\n",
    "        contour for contour in contours if cv2.contourArea(contour) >= 100\n",
    "    ]\n",
    "\n",
    "    return filtered_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {
    "marimo": {
     "name": "*extract_features_from_all_shapes"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_from_all_shapes(image_path, threshold_value=None):\n",
    "    feature_names = [\n",
    "        \"num_corners\",\n",
    "        \"solidity\",\n",
    "        \"aspect_ratio\",\n",
    "        \"circularity\",\n",
    "        \"hu1\",\n",
    "        \"hu2\",\n",
    "        \"hu3\",\n",
    "        \"hu4\",\n",
    "        \"hu5\",\n",
    "        \"hu6\",\n",
    "        \"hu7\",\n",
    "    ]\n",
    "\n",
    "    thresholded_image = preprocessing(image_path, threshold_value)\n",
    "    contours = find_all_contours(thresholded_image)\n",
    "    mo.output.append(f\"Found {len(contours)} contours in the image.\")\n",
    "\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "\n",
    "    all_contours_features = []\n",
    "    for contour in contours:\n",
    "        all_contours_features.append(extract_features_from_contour(contour))\n",
    "\n",
    "    df = pd.DataFrame(all_contours_features, columns=feature_names)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='font-size: 12px'>Counter({&#x27;circle&#x27;: 3, &#x27;triangle&#x27;: 3, &#x27;pentagon&#x27;: 2, &#x27;oval&#x27;: 1, &#x27;parallelogram&#x27;: 1})</pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_shape_image = mo.notebook_dir() / \"shapes_used.jpeg\"\n",
    "all_shapes_features = extract_features_from_all_shapes(\n",
    "    multi_shape_image, threshold_value=250\n",
    ")\n",
    "predicted_shapes = model.predict(all_shapes_features)\n",
    "Counter(predicted_shapes)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
